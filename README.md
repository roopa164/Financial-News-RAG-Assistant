ğŸ—ï¸ Financial News RAG Assistant

An AI-powered Retrieval-Augmented Generation (RAG) system designed to provide factual, context-grounded answers about financial news. This project leverages a modular architecture with a FastAPI backend for heavy-lifting AI logic and a Streamlit frontend for a clean user interface.

ğŸ—ï¸ Project Architecture

The system is divided into two main components to ensure scalability and clean separation of concerns:

  - Backend (FastAPI): Exposes the RAG pipeline via a REST API. It handles query embedding, searching the Chroma vector database, and generating answers using gpt-4o-mini.

  - Frontend (Streamlit): A web dashboard where users can submit questions and view the AI's answer alongside the specific news snippets used as evidence.

ğŸ“ Folder Structure
Plaintext

AI_Project_2026/

      â”œâ”€â”€ src/                # Core logic (Brain)
      â”‚   â”œâ”€â”€ ingestion.py    # JSON Data -> ChromaDB
      â”‚   â””â”€â”€ generation.py   # RAG Chain logic
      â”œâ”€â”€ app.py              # FastAPI Server (The Engine)
      â”œâ”€â”€ ui.py               # Streamlit App (The Face)
      â”œâ”€â”€ chroma_db/          # Vector Database storage
      â”œâ”€â”€ .env                # API Keys (Excluded from Git)
      â””â”€â”€ requirements.txt    # Project dependencies
ğŸ› ï¸ Installation & Setup

Clone the repository:

    Bash
    
    git clone <your-repo-url>
    cd AI_Project_2026
    Install dependencies:

    Bash
    
    pip install -r requirements.txt
Configure Environment Variables: Create a .env file in the root directory and add your OpenAI key:

Plaintext

    OPENAI_API_KEY=sk-xxxx...
ğŸš€ How to Run

You need to run the backend and frontend in separate terminal windows.

Step 1: Start the FastAPI Backend
      
      uvicorn app:app --reload
The API will be available at http://127.0.0.1:8000. You can view the interactive API docs at /docs.

Step 2: Start the Streamlit Frontend
   
    
    streamlit run ui.py
The dashboard will open automatically in your browser.

ğŸ“Š Evaluation & Metrics

This project uses the Ragas framework to measure performance across:

    Faithfulness: Ensuring the AI doesn't hallucinate.

    Answer Relevance: Checking if the answer actually addresses the user's query.

    Context Precision: Measuring how "noisy" the retrieved news snippets are.

ğŸ’¡ Implementation Note

This project uses langchain-classic to maintain compatibility with the RetrievalQA chain while benefiting from the speed of the 2026 LangChain v1.x core.
